{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb893207-3c4c-48fb-b90c-ad912464dde0",
   "metadata": {},
   "source": [
    "# Data Wrangling and Feature Engineering for RL Environment\n",
    "This notebook preprocesses and engineers features from raw trading data to prepare it for Soft Actor-Critic training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486dadad-9745-4c17-9a15-54f8c9f2067b",
   "metadata": {},
   "source": [
    "### Intraday ETF Data Processing and Feature Engineering\n",
    "\n",
    "This cell handles the complete data preparation pipeline for intraday ETF data before modeling.\n",
    "\n",
    "Steps performed:\n",
    "\n",
    "1. Data download  \n",
    "   - Fetches 2-minute interval OHLCV data from Yahoo Finance for the following ETFs:  \n",
    "     `SPY`, `QQQ`, `IWM`, `TLT`, `GLD`, `XLE`, `XLF`, `EEM`, `HYG`, `DBC`.  \n",
    "   - Period: from `2025-08-19` to `2025-10-09`.  \n",
    "   - Data is auto-adjusted for splits and dividends.\n",
    "\n",
    "2. Data cleaning  \n",
    "   - Restricts to standard fields: `Open`, `High`, `Low`, `Close`, `Volume`.  \n",
    "   - Ensures timestamps are localized to `America/New_York`.  \n",
    "   - Trims to regular U.S. trading hours (`09:30`–`16:00`).  \n",
    "   - Applies forward and backward filling (up to 5 intervals) to patch short gaps.  \n",
    "   - Removes empty rows and sorts data chronologically.  \n",
    "   - Saves the cleaned price panel to `data/processed/etfs_2m_clean.pkl`.\n",
    "\n",
    "3. Feature construction  \n",
    "   - Uses `build_all_features` to generate engineered features for each ETF individually.  \n",
    "   - Ensures a consistent multi-index format `(Ticker, Feature)`.  \n",
    "   - Removes raw OHLCV fields to retain only derived features.\n",
    "\n",
    "4. Normalization  \n",
    "   - Applies z-score normalization feature-wise across the entire dataset:  \n",
    "     `(x - mean) / (std + 1e-9)`  \n",
    "   - Handles missing and infinite values by dropping or replacing as needed.  \n",
    "   - Saves the normalized feature matrix to `data/processed/etfs_2m_features_clean.pkl`.\n",
    "\n",
    "5. Verification  \n",
    "   - Ensures correct multi-index structure.  \n",
    "   - Computes and displays average feature variance across all tickers as a quick sanity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7088d7e2-4868-4af7-970d-b5f9620c2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n",
      "C:\\Users\\mithi\\AppData\\Local\\Temp\\ipykernel_12136\\719646459.py:38: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(axis=1, level=0).ffill(limit=5).bfill(limit=5)\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:7: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"returns\"] = df[\"Close\"].pct_change()\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:9: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"momentum_5\"] = df[\"Close\"].pct_change(5)\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:10: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"momentum_20\"] = df[\"Close\"].pct_change(20)\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:28: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"vol_change\"] = df[\"Volume\"].pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clean panel saved: (2128, 50)\n",
      " Raw feature matrix: (2108, 130)\n",
      " Normalized features saved: (2108, 80)\n",
      " Feature variance summary:\n",
      "Feature\n",
      "rsi              1.000000\n",
      "zscore           1.000000\n",
      "vol_change       1.000000\n",
      "macd             1.000000\n",
      "momentum_20      0.999999\n",
      "momentum_5       0.999999\n",
      "returns          0.999997\n",
      "volatility_20    0.999995\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from src.utils.features import add_features, build_all_features  \n",
    "\n",
    "\n",
    "# Downloading and cleaning intraday price data for the selected ETFs\n",
    "\n",
    "tickers = [\"SPY\", \"QQQ\", \"IWM\", \"TLT\", \"GLD\", \"XLE\", \"XLF\", \"EEM\", \"HYG\", \"DBC\"]\n",
    "\n",
    "raw = yf.download(\n",
    "    tickers=tickers,\n",
    "    start=\"2025-08-19\",\n",
    "    end=\"2025-10-09\",\n",
    "    interval=\"2m\",\n",
    "    group_by=\"ticker\",\n",
    "    auto_adjust=True,\n",
    "    threads=True\n",
    ")\n",
    "\n",
    "def clean_panel(raw):\n",
    "    \"\"\"\n",
    "    Cleans raw Yahoo Finance panel data:\n",
    "    - Restricts to standard OHLCV fields\n",
    "    - Localizes to NY time zone if missing\n",
    "    - Trims to regular trading hours\n",
    "    - Forward/backward fills short gaps\n",
    "    - Drops entirely empty rows\n",
    "    \"\"\"\n",
    "    fields = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    df = raw.dropna(how=\"all\")\n",
    "    df = df.loc[:, pd.IndexSlice[:, fields]]\n",
    "    df = df.sort_index()\n",
    "    if df.index.tz is None:\n",
    "        df = df.tz_localize(\"America/New_York\", nonexistent=\"shift_forward\", ambiguous=\"NaT\")\n",
    "    df = df.between_time(\"09:30\", \"16:00\")\n",
    "    df = df.groupby(axis=1, level=0).ffill(limit=5).bfill(limit=5)\n",
    "    df = df.dropna(how=\"all\")\n",
    "    return df\n",
    "\n",
    "panel = clean_panel(raw)\n",
    "\n",
    "-\n",
    "#Saving cleaned price panel to disk for reproducibility\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "panel.to_pickle(\"data/processed/etfs_2m_clean.pkl\")\n",
    "print(\" Clean panel saved:\", panel.shape)\n",
    "\n",
    "\n",
    "# Feature construction per ticker, each ticker is processed individually using the custom feature builder\n",
    "-\n",
    "feat = build_all_features(panel)\n",
    "print(\" Raw feature matrix:\", feat.shape)\n",
    "\n",
    "# Standardising column structure to a consistent multiIndex (Ticker, Feature)\n",
    "if feat.columns.nlevels == 3:\n",
    "    feat.columns = feat.columns.droplevel(2)\n",
    "feat.columns.set_names([\"Ticker\", \"Feature\"], inplace=True)\n",
    "\n",
    "# need to remove raw OHLCV fields from the feature set to keep only engineered features\n",
    "\n",
    "drop_fields = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "feat = feat.drop(columns=drop_fields, level=\"Feature\", errors=\"ignore\")\n",
    "\n",
    "# normalising feature-wise z-scoring across the entire dataset to ensure standardisation\n",
    "\n",
    "feat = (\n",
    "    feat.T\n",
    "    .groupby(level=\"Feature\")\n",
    "    .apply(lambda x: (x - x.mean()) / (x.std() + 1e-9))\n",
    "    .T\n",
    ")\n",
    "\n",
    "\n",
    "#final cleanup and persistence of normalised feature matrix\n",
    "\n",
    "feat = feat.replace([np.inf, -np.inf], np.nan).dropna(how=\"all\")\n",
    "feat.to_pickle(\"data/processed/etfs_2m_features_clean.pkl\")\n",
    "print(\" Normalized features saved:\", feat.shape)\n",
    "\n",
    "\n",
    "# sanity check to verify successful normalisation\n",
    "\n",
    "if feat.columns.nlevels > 2:\n",
    "    feat.columns = feat.columns.droplevel(list(range(feat.columns.nlevels - 2)))\n",
    "\n",
    "# Rebuild MultiIndex with clear level names\n",
    "feat.columns = pd.MultiIndex.from_tuples(feat.columns, names=[\"Ticker\", \"Feature\"])\n",
    "\n",
    "# Calculate average standard deviation per feature across tickers\n",
    "feat_var = (\n",
    "    feat.T\n",
    "    .groupby(level=\"Feature\")\n",
    "    .std()\n",
    "    .mean(axis=1)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\" Feature variance summary:\")\n",
    "print(feat_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463150bc-3e8e-4516-9053-cb914eefc08e",
   "metadata": {},
   "source": [
    "### Turbulence Index Calculation\n",
    "\n",
    "This cell defines the `compute_turbulence` function, which quantifies market turbulence using the Mahalanobis distance over a rolling window of past returns.  \n",
    "The idea is to measure how statistically unusual the current return vector is compared to its recent historical distribution.\n",
    "\n",
    "Mechanics:\n",
    "- For each time step after an initial `window` period (default = 390 observations), the function:\n",
    "  1. Extracts the rolling historical return matrix.\n",
    "  2. Computes its mean vector (`μ`) and covariance matrix (`Σ`).\n",
    "  3. Calculates the Mahalanobis distance between the current return vector and the historical mean:\n",
    "     \\[\n",
    "     D_M = \\sqrt{(x - \\mu)^T \\Sigma^{-1} (x - \\mu)}\n",
    "     \\]\n",
    "  4. Records this as the turbulence measure.\n",
    "- If the covariance matrix is singular (non-invertible), it assigns `NaN` for that point.\n",
    "\n",
    "Output:\n",
    "A `pandas.Series` of turbulence scores aligned with the original index, where higher values indicate greater deviation from recent market behavior — i.e., more \"turbulent\" conditions.\n",
    "\n",
    "In the current prototype this is not taken as a feature, but I kept the function since it would be useful in a future extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f751f16e-7459-46fb-b0b0-b7fca01d1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_turbulence(r1, window=390):\n",
    "    \"\"\"\n",
    "    Computes a turbulence index using Mahalanobis distance over a rolling window.\n",
    "    This measures how unusual the current return vector is relative to its recent history.\n",
    "    \"\"\"\n",
    "\n",
    "    turb = []\n",
    "    idx = r1.index\n",
    "\n",
    "    \n",
    "    for i in range(window, len(r1)):\n",
    "        \n",
    "        hist = r1.iloc[i - window:i]\n",
    "\n",
    "        \n",
    "        mu = hist.mean().values\n",
    "        cov = hist.cov().values\n",
    "\n",
    "        \n",
    "        if np.linalg.det(cov) <= 0:\n",
    "            turb.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        diff = r1.iloc[i].values - mu\n",
    "        m_dist = np.sqrt(diff.T @ np.linalg.inv(cov) @ diff)\n",
    "        turb.append(m_dist)\n",
    "\n",
    "    \n",
    "    turb = pd.Series(turb, index=idx[window:])\n",
    "    return turb.reindex(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b27744-2ff8-4f1b-9c57-206a04c9a9cc",
   "metadata": {},
   "source": [
    "### Transaction Cost and Execution Modeling Utilities\n",
    "\n",
    "This module defines helper functions for estimating trading costs, liquidity effects, and execution prices based on market microstructure proxies.\n",
    "\n",
    "Functions included:\n",
    "\n",
    "1. `spread_proxy(high, low)`  \n",
    "   Estimates the bid–ask half-spread from intrabar high–low ranges.  \n",
    "   Useful when direct spread data is unavailable.  \n",
    "   Formula: `(high - low) / (0.5 * (high + low)) * 0.25`\n",
    "\n",
    "2. `realized_vol(close, win=60)`  \n",
    "   Computes rolling realized volatility as the standard deviation of percentage returns over a specified window.  \n",
    "   Acts as a simple measure of short-term price variability.\n",
    "\n",
    "3. `participation(dollar_trade, price, volume)`  \n",
    "   Calculates the participation rate of a trade relative to the total dollar volume in the bar.  \n",
    "   Ensures the trade size remains within realistic liquidity limits.\n",
    "\n",
    "4. `exec_price(side, mid, half_spread, sigma, dt_min, part, k=0.6, lam=2e-4)`  \n",
    "   Models the executed trade price including spread, drift, and market impact components.  \n",
    "   - `side` determines trade direction (+1 buy, -1 sell).  \n",
    "   - `drift` term scales with volatility and time.  \n",
    "   - `impact` term grows quadratically with participation rate.\n",
    "\n",
    "5. `turnover_l1(w_new, w_old)`  \n",
    "   Computes L1 turnover as the sum of absolute changes in portfolio weights between two time steps.  \n",
    "   Serves as a penalty for frequent rebalancing.\n",
    "\n",
    "Saved as a script in `costs.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67b920dc-3d46-4792-bf07-2cf9ea8b3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/costs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/costs.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def spread_proxy(high, low):\n",
    "    \"\"\"\n",
    "    Estimates the bid-ask half-spread using high–low ranges.\n",
    "    Acts as a proxy when direct spread data is unavailable.\n",
    "    \"\"\"\n",
    "    rng = (high - low).clip(lower=0)\n",
    "    mid = 0.5 * (high + low)\n",
    "    sp = (rng / mid).fillna(0.0)\n",
    "    return 0.25 * sp  # Scales the range to approximate half-spread\n",
    "\n",
    "def realized_vol(close, win=60):\n",
    "    \"\"\"\n",
    "    Computes rolling realized volatility based on percentage returns.\n",
    "    Uses a simple standard deviation over a specified window.\n",
    "    \"\"\"\n",
    "    r = close.pct_change()\n",
    "    return r.rolling(win).std().fillna(0.0)\n",
    "\n",
    "def participation(dollar_trade, price, volume):\n",
    "    \"\"\"\n",
    "    Calculates participation rate relative to the dollar volume of the bar.\n",
    "    Used to cap trading volume relative to available liquidity.\n",
    "    \"\"\"\n",
    "    dollar_bar = (price * volume).replace(0, np.nan)\n",
    "    return (dollar_trade / dollar_bar).fillna(0.0).clip(lower=0.0)\n",
    "\n",
    "def exec_price(side, mid, half_spread, sigma, dt_min, part, k=0.6, lam=2e-4):\n",
    "    \"\"\"\n",
    "    Models execution price with drift and impact components.\n",
    "    - side: trade direction (+1 buy, -1 sell, 0 no trade)\n",
    "    - mid: current mid price\n",
    "    - half_spread: estimated half-spread\n",
    "    - sigma: local volatility estimate\n",
    "    - dt_min: time increment in minutes\n",
    "    - part: participation rate\n",
    "    - k: drift scaling coefficient\n",
    "    - lam: impact parameter\n",
    "    \"\"\"\n",
    "    drift = k * sigma * np.sqrt(max(dt_min, 1.0))\n",
    "    impact = lam * (part ** 2)\n",
    "    if side > 0:\n",
    "        px = mid * (1.0 + half_spread + drift + impact)\n",
    "    elif side < 0:\n",
    "        px = mid * (1.0 - half_spread - drift - impact)\n",
    "    else:\n",
    "        px = mid\n",
    "    return px\n",
    "\n",
    "def turnover_l1(w_new, w_old):\n",
    "    \"\"\"\n",
    "    L1 turnover penalty: sum of absolute changes in portfolio weights.\n",
    "    Used to penalize excessive rebalancing.\n",
    "    \"\"\"\n",
    "    return np.abs(w_new - w_old).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ca8a8-7c75-496b-ade0-a0707f674648",
   "metadata": {},
   "source": [
    "### Portfolio Environment Class\n",
    "\n",
    "This module defines `PortfolioEnv`, a lightweight simulation environment for multi-asset portfolio management with execution costs, risk penalties, and liquidity constraints.  \n",
    "It is designed for reinforcement learning or rule-based allocation strategies that interact step-by-step with market data.\n",
    "\n",
    "Key components:\n",
    "\n",
    "1. Initialization  \n",
    "   - Inputs a price panel with fields `Close`, `High`, `Low`, and `Volume`.  \n",
    "   - Computes half-spread and realized volatility proxies using functions from `src.utils.costs`.  \n",
    "   - Defines simulation parameters:  \n",
    "     - `freq_min`: time step size in minutes  \n",
    "     - `start_equity`: initial portfolio value  \n",
    "     - `part_cap`: maximum participation rate per trade  \n",
    "     - `k`, `lam`: drift and impact coefficients for execution model  \n",
    "     - `gamma_bar`: annualized risk aversion, rescaled to per-minute  \n",
    "     - `eta_turnover`: turnover penalty weight  \n",
    "\n",
    "2. Reset  \n",
    "   - Initializes state variables including equity, cash, share positions, and weights.  \n",
    "   - Returns the initial observation containing current weights and equity.\n",
    "\n",
    "3. Observation  \n",
    "   - `_obs()` returns the observable state as a dictionary with `weights` and `equity`.\n",
    "\n",
    "4. Step function  \n",
    "   - Executes one portfolio update step given a target weight vector `w_target`.  \n",
    "   - Performs:  \n",
    "     - Weight normalization and participation capping  \n",
    "     - Execution price estimation using `exec_price`  \n",
    "     - Trade cash flow and position update  \n",
    "     - Equity and weight recalculation at next time step  \n",
    "   - Applies penalties for:  \n",
    "     - Instantaneous variance (risk)  \n",
    "     - Turnover (rebalancing cost)  \n",
    "     - Drift (allocation shift regularization)  \n",
    "   - Computes realized return from price change and aggregates into a reward:  \n",
    "     `reward = tanh((pnl - risk_pen - tvr_pen - drift_pen) * 20)`\n",
    "\n",
    "5. Output  \n",
    "   - Returns updated observation, computed reward, termination flag, and an info dictionary containing:  \n",
    "     - `pnl_ret`: realized return  \n",
    "     - `risk_pen`: risk penalty  \n",
    "     - `tvr_pen`: turnover penalty  \n",
    "     - `equity`: current portfolio value  \n",
    "\n",
    "The environment progresses through each time step of intraday market data, enabling sequential decision-making under realistic market frictions.\n",
    "\n",
    "Saved as a script in `portfolio_env.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7218d22c-a0e1-4fc1-b333-78dce19e09d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/env/portfolio_env.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/env/portfolio_env.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.utils.costs import spread_proxy, realized_vol, participation, exec_price, turnover_l1\n",
    "\n",
    "\n",
    "class PortfolioEnv:\n",
    "    \"\"\"\n",
    "    A simulation environment for multi-asset portfolio trading with market frictions,\n",
    "    transaction costs, and risk penalties.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    prices : DataFrame\n",
    "        Multi-indexed price panel containing OHLCV data for multiple tickers.\n",
    "    freq_min : int\n",
    "        Time step size in minutes.\n",
    "    start_equity : float\n",
    "        Initial portfolio equity.\n",
    "    part_cap : float\n",
    "        Maximum participation rate per trade.\n",
    "    k : float\n",
    "        Drift scaling coefficient in execution model.\n",
    "    lam : float\n",
    "        Market impact parameter.\n",
    "    gamma_bar : float\n",
    "        Annualized risk aversion, converted to per-minute scale internally.\n",
    "    eta_turnover : float\n",
    "        Turnover penalty weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prices,\n",
    "        freq_min=1,\n",
    "        start_equity=1_000_000,\n",
    "        part_cap=0.05,\n",
    "        k=0.6,\n",
    "        lam=2e-4,\n",
    "        gamma_bar=12,\n",
    "        eta_turnover=0.001\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the environment with price data and trading parameters.\n",
    "        Precomputes spread and volatility proxies used in transaction and risk modeling.\n",
    "        \"\"\"\n",
    "        self.prices = prices\n",
    "        self.close = prices.loc[:, pd.IndexSlice[:, \"Close\"]]\n",
    "        self.high = prices.loc[:, pd.IndexSlice[:, \"High\"]]\n",
    "        self.low = prices.loc[:, pd.IndexSlice[:, \"Low\"]]\n",
    "        self.vol = prices.loc[:, pd.IndexSlice[:, \"Volume\"]]\n",
    "        self.mid = self.close\n",
    "\n",
    "        self.half_spread = spread_proxy(self.high, self.low)\n",
    "        self.sigma = realized_vol(self.close, win=60)\n",
    "\n",
    "        self.part_cap = part_cap\n",
    "        self.k = k\n",
    "        self.lam = lam\n",
    "        self.freq_min = freq_min\n",
    "        self.gamma = gamma_bar / (252 * 390)\n",
    "        self.eta_turnover = eta_turnover\n",
    "        self.start_equity = start_equity\n",
    "        self.tickers = self.close.columns.get_level_values(0).unique()\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to its initial state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Initial observation containing portfolio weights and equity.\n",
    "        \"\"\"\n",
    "        self.t = 1\n",
    "        self.equity = float(self.start_equity)\n",
    "        self.w = np.zeros(len(self.tickers))\n",
    "        self.q = np.zeros(len(self.tickers))\n",
    "        self.cash = float(self.start_equity)\n",
    "        return self._obs()\n",
    "\n",
    "    def _obs(self):\n",
    "        \"\"\"\n",
    "        Returns the current observable state of the environment.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary with current weights and equity.\n",
    "        \"\"\"\n",
    "        return {\"weights\": self.w.copy(), \"equity\": float(self.equity)}\n",
    "\n",
    "    def step(self, w_target):\n",
    "        \"\"\"\n",
    "        Advances the environment by one step given a target weight allocation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        w_target : array-like\n",
    "            Target portfolio weights for all tickers.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            observation : dict\n",
    "                Updated weights and equity.\n",
    "            reward : float\n",
    "                Scalar reward value after applying penalties.\n",
    "            done : bool\n",
    "                Whether the simulation has reached the final time step.\n",
    "            info : dict\n",
    "                Diagnostic metrics including pnl, penalties, and equity.\n",
    "        \"\"\"\n",
    "        w_target = np.array(w_target).flatten()\n",
    "        w_target = np.clip(w_target, 0, 1)\n",
    "        if w_target.sum() > 0:\n",
    "            w_target /= w_target.sum()\n",
    "\n",
    "        idx = self.close.index[self.t]\n",
    "        idx_next = self.close.index[min(self.t + 1, len(self.close) - 1)]\n",
    "\n",
    "        mid = np.nan_to_num(self.mid.loc[idx].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        hs = np.nan_to_num(self.half_spread.loc[idx].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        sg = np.nan_to_num(self.sigma.loc[idx].values, nan=1e-6, posinf=1e-6, neginf=1e-6)\n",
    "        vol = np.nan_to_num(self.vol.loc[idx].values, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "\n",
    "        dollar_pos_now = self.q * mid\n",
    "        port_now = float(self.cash + np.sum(dollar_pos_now))\n",
    "        self.equity = max(port_now, 1.0)\n",
    "\n",
    "        delta_w = w_target - self.w\n",
    "\n",
    "        desired_notional = delta_w * self.equity\n",
    "        part = participation(pd.Series(np.abs(desired_notional)), pd.Series(mid), pd.Series(vol)).values\n",
    "        part = np.nan_to_num(np.clip(part, 0, self.part_cap), nan=0.0)\n",
    "        feasible_notional = desired_notional * part\n",
    "        signed_shares = np.nan_to_num(feasible_notional / np.maximum(mid, 1e-12))\n",
    "\n",
    "        exec_px = np.array([\n",
    "            exec_price(np.sign(dw), m, h, sgm, self.freq_min, p, self.k, self.lam)\n",
    "            for dw, m, h, sgm, p in zip(delta_w, mid, hs, sg, part)\n",
    "        ])\n",
    "        exec_px = np.nan_to_num(exec_px, nan=mid, posinf=mid, neginf=mid)\n",
    "\n",
    "        trade_cash_flow = float(np.sum(signed_shares * exec_px))\n",
    "        self.cash -= trade_cash_flow\n",
    "        self.q += signed_shares\n",
    "\n",
    "        next_px = np.nan_to_num(self.mid.loc[idx_next].values, nan=mid, posinf=mid, neginf=mid)\n",
    "        portfolio_value = float(self.cash + np.sum(self.q * next_px))\n",
    "        self.equity = max(portfolio_value, 1.0)\n",
    "\n",
    "        dollar_pos_next = self.q * next_px\n",
    "        self.w = np.clip(np.nan_to_num(dollar_pos_next / np.maximum(self.equity, 1e-12)), 0, 1)\n",
    "\n",
    "        var_diag = np.nan_to_num((self.sigma.loc[idx] ** 2).values, nan=0.0)\n",
    "        risk_pen = 0.5 * self.gamma * float(np.dot(self.w, var_diag * self.w))\n",
    "\n",
    "        prev_w = np.nan_to_num(dollar_pos_now / np.maximum(port_now, 1e-12))\n",
    "        tvr = turnover_l1(self.w, prev_w)\n",
    "        tvr_pen = self.eta_turnover * tvr\n",
    "\n",
    "        prev_idx = self.close.index[self.t - 1]\n",
    "        r_bar = np.nan_to_num(\n",
    "            self.mid.loc[idx_next].values / np.maximum(self.mid.loc[prev_idx].values, 1e-12) - 1.0,\n",
    "            nan=0.0,\n",
    "        )\n",
    "        pnl_ret = float(np.dot(self.w, r_bar))\n",
    "\n",
    "        drift_pen = np.clip(1e-5 * np.square(delta_w).sum(), 0, 1e-3)\n",
    "\n",
    "        raw = pnl_ret - risk_pen - tvr_pen - drift_pen\n",
    "        reward = float(np.clip(np.tanh(raw * 20.0), -1.0, 1.0))\n",
    "\n",
    "        info = {\n",
    "            \"pnl_ret\": pnl_ret,\n",
    "            \"risk_pen\": risk_pen,\n",
    "            \"tvr_pen\": tvr_pen,\n",
    "            \"equity\": float(self.equity)\n",
    "        }\n",
    "\n",
    "        self.t += 1\n",
    "        done = self.t >= len(self.close) - 1\n",
    "\n",
    "        return self._obs(), reward, done, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2dced2-5bf8-46e6-ba4e-8fcc9c39418c",
   "metadata": {},
   "source": [
    "### PortfolioGym Environment Wrapper\n",
    "\n",
    "This cell defines the `PortfolioGym` class, a `gymnasium`-compatible wrapper around `PortfolioEnv`, allowing direct integration of the trading environment with reinforcement learning frameworks.\n",
    "\n",
    "Key points:\n",
    "\n",
    "1. Purpose  \n",
    "   - Provides a standardized RL interface (`reset`, `step`, `render`) for portfolio management tasks.  \n",
    "   - Enables agents to interact with financial data through continuous observation and action spaces.\n",
    "\n",
    "2. Components  \n",
    "   - `core`: an instance of `PortfolioEnv` that handles trading logic, execution costs, and rewards.  \n",
    "   - `feature_df`: optional external features (e.g., macro indicators, technical signals) aligned with the same timestamps as the price data.  \n",
    "   - `observation_space`: continuous vector combining equity, current portfolio weights, and optional features.  \n",
    "   - `action_space`: continuous vector of target weights for each asset.\n",
    "\n",
    "3. Workflow  \n",
    "   - `reset()`: initializes the portfolio and returns the first observation.  \n",
    "   - `step(action)`: executes trades, updates equity, computes reward, and returns the next state.  \n",
    "   - `render()`: prints a short summary of the current timestep and portfolio equity.\n",
    "\n",
    "4. Design  \n",
    "   - Handles NaN and non-finite values gracefully for numerical stability.  \n",
    "   - Normalizes feature vectors and clips extreme values to maintain RL training stability.  \n",
    "   - Fully compliant with Gymnasium API, supporting integration with libraries such as `Stable-Baselines3`, `Ray RLlib`, or `CleanRL`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62230a7-2f1e-4947-b1c1-0c3f6456a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/env/portfolio_gym.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/env/portfolio_gym.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from src.env.portfolio_env import PortfolioEnv\n",
    "\n",
    "\n",
    "class PortfolioGym(gym.Env):\n",
    "    \"\"\"\n",
    "    Gymnasium-compatible wrapper around the PortfolioEnv environment.\n",
    "\n",
    "    This class provides a standardized reinforcement learning interface for\n",
    "    portfolio management tasks, enabling interaction through observations,\n",
    "    actions, and rewards in compliance with Gymnasium API conventions.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    core : PortfolioEnv\n",
    "        Core environment handling portfolio mechanics, execution, and reward logic.\n",
    "    feature_df : DataFrame or None\n",
    "        Optional feature matrix aligned with the time index of the price data.\n",
    "    tickers : list\n",
    "        List of asset tickers included in the environment.\n",
    "    n_assets : int\n",
    "        Number of tradable assets.\n",
    "    observation_space : gym.spaces.Box\n",
    "        Continuous space containing equity, portfolio weights, and optional features.\n",
    "    action_space : gym.spaces.Box\n",
    "        Continuous space representing target portfolio weights.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, prices, feature_df=None, start_equity=1_000_000):\n",
    "        \"\"\"\n",
    "        Initialize the Gym-compatible portfolio environment.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prices : DataFrame\n",
    "            Multi-indexed price panel containing OHLCV data.\n",
    "        feature_df : DataFrame, optional\n",
    "            External feature matrix to augment observations.\n",
    "        start_equity : float, default=1_000_000\n",
    "            Initial portfolio value.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.core = PortfolioEnv(prices, start_equity=start_equity)\n",
    "        self.feature_df = feature_df\n",
    "        self.tickers = self.core.tickers\n",
    "        self.n_assets = len(self.tickers)\n",
    "\n",
    "        feat_dim = 0 if feature_df is None else feature_df.shape[1]\n",
    "        obs_dim = 1 + self.n_assets + feat_dim\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.n_assets,), dtype=np.float32)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        Reset the environment and return the initial observation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int, optional\n",
    "            Random seed for reproducibility.\n",
    "        options : dict, optional\n",
    "            Additional reset options.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            observation : ndarray\n",
    "                Normalized observation vector after reset.\n",
    "            info : dict\n",
    "                Auxiliary information (empty by default).\n",
    "        \"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        obs_core = self.core.reset()\n",
    "        obs = self._build_obs(obs_core)\n",
    "        return obs.astype(np.float32), {}\n",
    "\n",
    "    def _build_obs(self, core_obs):\n",
    "        \"\"\"\n",
    "        Construct the observation vector from core environment data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        core_obs : dict\n",
    "            Core observation dictionary containing weights and equity.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            Flattened and normalized observation vector.\n",
    "        \"\"\"\n",
    "        equity = float(core_obs[\"equity\"])\n",
    "        w = np.array(core_obs[\"weights\"], dtype=np.float32)\n",
    "\n",
    "        if self.feature_df is not None:\n",
    "            t = min(self.core.t, len(self.feature_df) - 1)\n",
    "            f = self.feature_df.iloc[t].to_numpy(dtype=np.float32)\n",
    "            f = np.nan_to_num(f, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            f = (f - np.mean(f)) / (np.std(f) + 1e-8)\n",
    "            obs = np.concatenate(([equity], w, f))\n",
    "        else:\n",
    "            obs = np.concatenate(([equity], w))\n",
    "\n",
    "        return np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Advance the environment one step given an action.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : ndarray\n",
    "            Target portfolio weights to apply.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            observation : ndarray\n",
    "                Updated observation vector.\n",
    "            reward : float\n",
    "                Scalar reward signal from the core environment.\n",
    "            terminated : bool\n",
    "                Whether the episode has reached its end.\n",
    "            truncated : bool\n",
    "                Whether the episode was truncated externally.\n",
    "            info : dict\n",
    "                Diagnostic and performance metrics.\n",
    "        \"\"\"\n",
    "        obs_core, reward, done, info = self.core.step(action)\n",
    "\n",
    "        if not np.isfinite(reward):\n",
    "            print(f\"[Warning] Non-finite reward at t={self.core.t}: {reward}\")\n",
    "            reward = 0.0\n",
    "\n",
    "        obs = self._build_obs(obs_core)\n",
    "\n",
    "        if np.isnan(obs).any():\n",
    "            print(f\"[NaN detected in obs] t={self.core.t}, replacing with zeros.\")\n",
    "            obs = np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if np.isnan(reward):\n",
    "            reward = 0.0\n",
    "\n",
    "        obs = np.clip(obs, -1e6, 1e6)\n",
    "        reward = float(np.clip(reward, -1e3, 1e3))\n",
    "\n",
    "        terminated = bool(done)\n",
    "        truncated = False\n",
    "\n",
    "        return obs.astype(np.float32), reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Print a simple textual representation of the current simulation state.\n",
    "\n",
    "        Displays the current step index and portfolio equity for quick debugging.\n",
    "        \"\"\"\n",
    "        print(f\"Step {self.core.t}, Equity {self.core.equity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed4b757-9129-4241-bacb-e926135bca33",
   "metadata": {},
   "source": [
    "### Feature Engineering Utilities\n",
    "\n",
    "This cell defines helper functions for constructing engineered features from raw OHLCV data, both at the single-ticker and multi-ticker level.\n",
    "\n",
    "Functions:\n",
    "\n",
    "1. `add_features(df)`  \n",
    "   Enriches a single-ticker dataframe with common statistical and technical indicators.  \n",
    "   Expects columns `['Open', 'High', 'Low', 'Close', 'Volume']`.  \n",
    "   Generated features include:\n",
    "   - `returns`: percentage change in closing price  \n",
    "   - `volatility_20`: 20-period rolling standard deviation of returns  \n",
    "   - `momentum_5`, `momentum_20`: short and medium-term price momentum  \n",
    "   - `rsi`: 14-period Relative Strength Index computed from average gains and losses  \n",
    "   - `macd`: Moving Average Convergence Divergence (`EMA12 - EMA26`)  \n",
    "   - `zscore`: rolling z-score of closing price relative to a 20-period mean and standard deviation  \n",
    "   - `vol_change`: percentage change in trading volume  \n",
    "   The function returns a dataframe with NaN values dropped.\n",
    "\n",
    "2. `build_all_features(panel)`  \n",
    "   Applies `add_features` to each ticker in a multi-indexed price panel and concatenates results.  \n",
    "   The returned dataframe uses a two-level column MultiIndex in the format `(Ticker, Feature)`, suitable for multi-asset feature modeling or machine learning pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5199c8c7-970c-4689-a62c-0e704e86e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/features.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enriches a single-ticker price dataframe with a set of standard technical indicators.\n",
    "    Assumes columns: ['Open', 'High', 'Low', 'Close', 'Volume'].\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"returns\"] = df[\"Close\"].pct_change()\n",
    "    df[\"volatility_20\"] = df[\"returns\"].rolling(20).std()\n",
    "\n",
    "    df[\"momentum_5\"] = df[\"Close\"].pct_change(5)\n",
    "    df[\"momentum_20\"] = df[\"Close\"].pct_change(20)\n",
    "\n",
    "    delta = df[\"Close\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-9)\n",
    "    df[\"rsi\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    ema12 = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    df[\"macd\"] = ema12 - ema26\n",
    "\n",
    "    df[\"zscore\"] = (df[\"Close\"] - df[\"Close\"].rolling(20).mean()) / (df[\"Close\"].rolling(20).std() + 1e-9)\n",
    "\n",
    "    df[\"vol_change\"] = df[\"Volume\"].pct_change()\n",
    "\n",
    "    return df.dropna()\n",
    "\n",
    "def build_all_features(panel):\n",
    "    \"\"\"\n",
    "    Applies the add_features function to each ticker in a multi-index price panel.\n",
    "    Returns a feature panel with a two-level column index: (Ticker, Feature).\n",
    "    \"\"\"\n",
    "    tickers = panel.columns.get_level_values(0).unique()\n",
    "    feat_list = []\n",
    "\n",
    "    \n",
    "    for t in tickers:\n",
    "        df_t = panel[t].copy()\n",
    "        df_feat = add_features(df_t)\n",
    "        feat_list.append(df_feat)\n",
    "\n",
    "    \n",
    "    feat = pd.concat(feat_list, axis=1, keys=tickers)\n",
    "    return feat\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
