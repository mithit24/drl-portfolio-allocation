{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb893207-3c4c-48fb-b90c-ad912464dde0",
   "metadata": {},
   "source": [
    "# Data Wrangling and Feature Engineering for RL Environment\n",
    "This notebook preprocesses and engineers features from raw trading data to prepare it for Soft Actor-Critic training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7088d7e2-4868-4af7-970d-b5f9620c2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n",
      "C:\\Users\\mithi\\AppData\\Local\\Temp\\ipykernel_12136\\719646459.py:38: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df = df.groupby(axis=1, level=0).ffill(limit=5).bfill(limit=5)\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:7: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"returns\"] = df[\"Close\"].pct_change()\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:9: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"momentum_5\"] = df[\"Close\"].pct_change(5)\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:10: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"momentum_20\"] = df[\"Close\"].pct_change(20)\n",
      "C:\\Users\\mithi\\drl-portfolio-allocation\\src\\utils\\features.py:28: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"vol_change\"] = df[\"Volume\"].pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clean panel saved: (2128, 50)\n",
      " Raw feature matrix: (2108, 130)\n",
      " Normalized features saved: (2108, 80)\n",
      " Feature variance summary:\n",
      "Feature\n",
      "rsi              1.000000\n",
      "zscore           1.000000\n",
      "vol_change       1.000000\n",
      "macd             1.000000\n",
      "momentum_20      0.999999\n",
      "momentum_5       0.999999\n",
      "returns          0.999997\n",
      "volatility_20    0.999995\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from src.utils.features import add_features, build_all_features  # assuming build_all_features uses add_features per ticker\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Download and clean intraday price data for the selected ETFs\n",
    "# ---------------------------------------------------------------------------\n",
    "tickers = [\"SPY\", \"QQQ\", \"IWM\", \"TLT\", \"GLD\", \"XLE\", \"XLF\", \"EEM\", \"HYG\", \"DBC\"]\n",
    "\n",
    "raw = yf.download(\n",
    "    tickers=tickers,\n",
    "    start=\"2025-08-19\",\n",
    "    end=\"2025-10-09\",\n",
    "    interval=\"2m\",\n",
    "    group_by=\"ticker\",\n",
    "    auto_adjust=True,\n",
    "    threads=True\n",
    ")\n",
    "\n",
    "def clean_panel(raw):\n",
    "    \"\"\"\n",
    "    Cleans raw Yahoo Finance panel data:\n",
    "    - Restricts to standard OHLCV fields\n",
    "    - Localizes to NY time zone if missing\n",
    "    - Trims to regular trading hours\n",
    "    - Forward/backward fills short gaps\n",
    "    - Drops entirely empty rows\n",
    "    \"\"\"\n",
    "    fields = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    df = raw.dropna(how=\"all\")\n",
    "    df = df.loc[:, pd.IndexSlice[:, fields]]\n",
    "    df = df.sort_index()\n",
    "    if df.index.tz is None:\n",
    "        df = df.tz_localize(\"America/New_York\", nonexistent=\"shift_forward\", ambiguous=\"NaT\")\n",
    "    df = df.between_time(\"09:30\", \"16:00\")\n",
    "    df = df.groupby(axis=1, level=0).ffill(limit=5).bfill(limit=5)\n",
    "    df = df.dropna(how=\"all\")\n",
    "    return df\n",
    "\n",
    "panel = clean_panel(raw)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Save cleaned price panel to disk for reproducibility\n",
    "# ---------------------------------------------------------------------------\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "panel.to_pickle(\"data/processed/etfs_2m_clean.pkl\")\n",
    "print(\" Clean panel saved:\", panel.shape)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Feature construction per ticker\n",
    "#    Each ticker is processed individually using the custom feature builder\n",
    "# ---------------------------------------------------------------------------\n",
    "feat = build_all_features(panel)\n",
    "print(\" Raw feature matrix:\", feat.shape)\n",
    "\n",
    "# Standardize column structure to a consistent MultiIndex (Ticker, Feature)\n",
    "if feat.columns.nlevels == 3:\n",
    "    feat.columns = feat.columns.droplevel(2)\n",
    "feat.columns.set_names([\"Ticker\", \"Feature\"], inplace=True)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. Remove raw OHLCV fields from the feature set to keep only engineered features\n",
    "# ---------------------------------------------------------------------------\n",
    "drop_fields = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "feat = feat.drop(columns=drop_fields, level=\"Feature\", errors=\"ignore\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5. Normalize features by feature-wise z-scoring across the entire dataset\n",
    "#    This ensures comparable scale across assets and features\n",
    "# ---------------------------------------------------------------------------\n",
    "feat = (\n",
    "    feat.T\n",
    "    .groupby(level=\"Feature\")\n",
    "    .apply(lambda x: (x - x.mean()) / (x.std() + 1e-9))\n",
    "    .T\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6. Final cleanup and persistence of normalized feature matrix\n",
    "# ---------------------------------------------------------------------------\n",
    "feat = feat.replace([np.inf, -np.inf], np.nan).dropna(how=\"all\")\n",
    "feat.to_pickle(\"data/processed/etfs_2m_features_clean.pkl\")\n",
    "print(\" Normalized features saved:\", feat.shape)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 7. Diagnostic: compute per-feature variance to verify successful normalization\n",
    "# ---------------------------------------------------------------------------\n",
    "# Drop extra column levels if present\n",
    "if feat.columns.nlevels > 2:\n",
    "    feat.columns = feat.columns.droplevel(list(range(feat.columns.nlevels - 2)))\n",
    "\n",
    "# Rebuild MultiIndex with clear level names\n",
    "feat.columns = pd.MultiIndex.from_tuples(feat.columns, names=[\"Ticker\", \"Feature\"])\n",
    "\n",
    "# Calculate average standard deviation per feature across tickers\n",
    "feat_var = (\n",
    "    feat.T\n",
    "    .groupby(level=\"Feature\")\n",
    "    .std()\n",
    "    .mean(axis=1)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\" Feature variance summary:\")\n",
    "print(feat_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f751f16e-7459-46fb-b0b0-b7fca01d1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_turbulence(r1, window=390):\n",
    "    \"\"\"\n",
    "    Computes a turbulence index using Mahalanobis distance over a rolling window.\n",
    "    This measures how unusual the current return vector is relative to its recent history.\n",
    "    \"\"\"\n",
    "\n",
    "    turb = []\n",
    "    idx = r1.index\n",
    "\n",
    "    # Iterate through the time series, starting after the initial window\n",
    "    for i in range(window, len(r1)):\n",
    "        # Extract historical return window\n",
    "        hist = r1.iloc[i - window:i]\n",
    "\n",
    "        # Compute historical mean and covariance matrix\n",
    "        mu = hist.mean().values\n",
    "        cov = hist.cov().values\n",
    "\n",
    "        # Skip periods where covariance matrix is singular or ill-conditioned\n",
    "        if np.linalg.det(cov) <= 0:\n",
    "            turb.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Compute Mahalanobis distance between current returns and historical distribution\n",
    "        diff = r1.iloc[i].values - mu\n",
    "        m_dist = np.sqrt(diff.T @ np.linalg.inv(cov) @ diff)\n",
    "        turb.append(m_dist)\n",
    "\n",
    "    # Align turbulence series with original index\n",
    "    turb = pd.Series(turb, index=idx[window:])\n",
    "    return turb.reindex(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67b920dc-3d46-4792-bf07-2cf9ea8b3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/costs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/costs.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def spread_proxy(high, low):\n",
    "    \"\"\"\n",
    "    Estimates the bid-ask half-spread using highâ€“low ranges.\n",
    "    Acts as a proxy when direct spread data is unavailable.\n",
    "    \"\"\"\n",
    "    rng = (high - low).clip(lower=0)\n",
    "    mid = 0.5 * (high + low)\n",
    "    sp = (rng / mid).fillna(0.0)\n",
    "    return 0.25 * sp  # Scales the range to approximate half-spread\n",
    "\n",
    "def realized_vol(close, win=60):\n",
    "    \"\"\"\n",
    "    Computes rolling realized volatility based on percentage returns.\n",
    "    Uses a simple standard deviation over a specified window.\n",
    "    \"\"\"\n",
    "    r = close.pct_change()\n",
    "    return r.rolling(win).std().fillna(0.0)\n",
    "\n",
    "def participation(dollar_trade, price, volume):\n",
    "    \"\"\"\n",
    "    Calculates participation rate relative to the dollar volume of the bar.\n",
    "    Used to cap trading volume relative to available liquidity.\n",
    "    \"\"\"\n",
    "    dollar_bar = (price * volume).replace(0, np.nan)\n",
    "    return (dollar_trade / dollar_bar).fillna(0.0).clip(lower=0.0)\n",
    "\n",
    "def exec_price(side, mid, half_spread, sigma, dt_min, part, k=0.6, lam=2e-4):\n",
    "    \"\"\"\n",
    "    Models execution price with drift and impact components.\n",
    "    - side: trade direction (+1 buy, -1 sell, 0 no trade)\n",
    "    - mid: current mid price\n",
    "    - half_spread: estimated half-spread\n",
    "    - sigma: local volatility estimate\n",
    "    - dt_min: time increment in minutes\n",
    "    - part: participation rate\n",
    "    - k: drift scaling coefficient\n",
    "    - lam: impact parameter\n",
    "    \"\"\"\n",
    "    drift = k * sigma * np.sqrt(max(dt_min, 1.0))\n",
    "    impact = lam * (part ** 2)\n",
    "    if side > 0:\n",
    "        px = mid * (1.0 + half_spread + drift + impact)\n",
    "    elif side < 0:\n",
    "        px = mid * (1.0 - half_spread - drift - impact)\n",
    "    else:\n",
    "        px = mid\n",
    "    return px\n",
    "\n",
    "def turnover_l1(w_new, w_old):\n",
    "    \"\"\"\n",
    "    L1 turnover penalty: sum of absolute changes in portfolio weights.\n",
    "    Used to penalize excessive rebalancing.\n",
    "    \"\"\"\n",
    "    return np.abs(w_new - w_old).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65e626d3-7fde-4f6b-906c-e433e601e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/env/portfolio_env.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/env/portfolio_env.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.utils.costs import spread_proxy, realized_vol, participation, exec_price, turnover_l1\n",
    "\n",
    "class PortfolioEnv:\n",
    "    def __init__(\n",
    "        self,\n",
    "        prices,\n",
    "        freq_min=1,\n",
    "        start_equity=1_000_000,\n",
    "        part_cap=0.05,\n",
    "        k=0.6,\n",
    "        lam=2e-4,\n",
    "        gamma_bar=12,\n",
    "        eta_turnover=0.001\n",
    "    ):\n",
    "        # Store raw price panel and extract core fields\n",
    "        self.prices = prices\n",
    "        self.close = prices.loc[:, pd.IndexSlice[:, \"Close\"]]\n",
    "        self.high  = prices.loc[:, pd.IndexSlice[:, \"High\"]]\n",
    "        self.low   = prices.loc[:, pd.IndexSlice[:, \"Low\"]]\n",
    "        self.vol   = prices.loc[:, pd.IndexSlice[:, \"Volume\"]]\n",
    "        self.mid   = self.close\n",
    "\n",
    "        # Precompute spread and volatility proxies used in execution cost and risk models\n",
    "        self.half_spread = spread_proxy(self.high, self.low)\n",
    "        self.sigma = realized_vol(self.close, win=60)\n",
    "\n",
    "        # Core trading and cost parameters\n",
    "        self.part_cap = part_cap\n",
    "        self.k = k\n",
    "        a = lam\n",
    "        self.lam = a\n",
    "        self.freq_min = freq_min\n",
    "        self.gamma = gamma_bar / (252 * 390)   # Convert annualized gamma to per-minute scale\n",
    "        self.eta_turnover = eta_turnover\n",
    "        self.start_equity = start_equity\n",
    "        self.tickers = self.close.columns.get_level_values(0).unique()\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # RESET\n",
    "    # ------------------------------------------------------\n",
    "    def reset(self):\n",
    "        # Initialize environment state: starting equity, positions, weights, and time index\n",
    "        self.t = 1\n",
    "        self.equity = float(self.start_equity)\n",
    "        self.w = np.zeros(len(self.tickers))\n",
    "        self.q = np.zeros(len(self.tickers))        # positions in shares\n",
    "        self.cash = float(self.start_equity)\n",
    "        return self._obs()\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # OBSERVATION\n",
    "    # ------------------------------------------------------\n",
    "    def _obs(self):\n",
    "        # Expose weights and current equity as the observation state\n",
    "        return {\"weights\": self.w.copy(), \"equity\": float(self.equity)}\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # STEP\n",
    "    # ------------------------------------------------------\n",
    "    def step(self, w_target):\n",
    "        # Clamp and normalize target weights to ensure valid portfolio allocation\n",
    "        w_target = np.array(w_target).flatten()\n",
    "        w_target = np.clip(w_target, 0, 1)\n",
    "        if w_target.sum() > 0:\n",
    "            w_target /= w_target.sum()\n",
    "\n",
    "        # Current and next index for price lookup\n",
    "        idx = self.close.index[self.t]\n",
    "        idx_next = self.close.index[min(self.t + 1, len(self.close) - 1)]\n",
    "\n",
    "        # Retrieve current price and liquidity state, replacing bad values\n",
    "        mid = np.nan_to_num(self.mid.loc[idx].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        hs  = np.nan_to_num(self.half_spread.loc[idx].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        sg  = np.nan_to_num(self.sigma.loc[idx].values, nan=1e-6, posinf=1e-6, neginf=1e-6)\n",
    "        vol = np.nan_to_num(self.vol.loc[idx].values,  nan=1.0, posinf=1.0, neginf=1.0)\n",
    "\n",
    "        # Calculate current portfolio value based on mid-prices\n",
    "        dollar_pos_now = self.q * mid\n",
    "        port_now = float(self.cash + np.sum(dollar_pos_now))\n",
    "        self.equity = max(port_now, 1.0)\n",
    "\n",
    "        # Compute target vs current weight difference\n",
    "        delta_w = w_target - self.w\n",
    "\n",
    "        # Convert target weight change into dollar notional and cap participation\n",
    "        desired_notional = delta_w * self.equity\n",
    "        part = participation(pd.Series(np.abs(desired_notional)), pd.Series(mid), pd.Series(vol)).values\n",
    "        part = np.nan_to_num(np.clip(part, 0, self.part_cap), nan=0.0)\n",
    "        feasible_notional = desired_notional * part\n",
    "        signed_shares = np.nan_to_num(feasible_notional / np.maximum(mid, 1e-12))\n",
    "\n",
    "        # Determine execution prices incorporating spread, drift, and impact\n",
    "        exec_px = np.array([\n",
    "            exec_price(np.sign(dw), m, h, sgm, self.freq_min, p, self.k, self.lam)\n",
    "            for dw, m, h, sgm, p in zip(delta_w, mid, hs, sg, part)\n",
    "        ])\n",
    "        exec_px = np.nan_to_num(exec_px, nan=mid, posinf=mid, neginf=mid)\n",
    "\n",
    "        # Apply cash impact of trades and update share positions\n",
    "        trade_cash_flow = float(np.sum(signed_shares * exec_px))\n",
    "        self.cash -= trade_cash_flow\n",
    "        self.q += signed_shares\n",
    "\n",
    "        # Revalue portfolio using next prices\n",
    "        next_px = np.nan_to_num(self.mid.loc[idx_next].values, nan=mid, posinf=mid, neginf=mid)\n",
    "        portfolio_value = float(self.cash + np.sum(self.q * next_px))\n",
    "        self.equity = max(portfolio_value, 1.0)\n",
    "\n",
    "        # Update portfolio weights based on new equity and prices\n",
    "        dollar_pos_next = self.q * next_px\n",
    "        self.w = np.clip(np.nan_to_num(dollar_pos_next / np.maximum(self.equity, 1e-12)), 0, 1)\n",
    "\n",
    "        # Compute risk penalty based on instantaneous variance estimate\n",
    "        var_diag = np.nan_to_num((self.sigma.loc[idx] ** 2).values, nan=0.0)\n",
    "        risk_pen = 0.5 * self.gamma * float(np.dot(self.w, var_diag * self.w))\n",
    "\n",
    "        # Compute turnover penalty relative to pre-trade weights\n",
    "        prev_w = np.nan_to_num(dollar_pos_now / np.maximum(port_now, 1e-12))\n",
    "        tvr = turnover_l1(self.w, prev_w)\n",
    "        tvr_pen = self.eta_turnover * tvr\n",
    "\n",
    "        # Calculate realized return using price change between previous and next ticks\n",
    "        prev_idx = self.close.index[self.t - 1]\n",
    "        r_bar = np.nan_to_num(\n",
    "            self.mid.loc[idx_next].values / np.maximum(self.mid.loc[prev_idx].values, 1e-12) - 1.0,\n",
    "            nan=0.0,\n",
    "        )\n",
    "        pnl_ret = float(np.dot(self.w, r_bar))\n",
    "\n",
    "        # Add small drift penalty to discourage frequent allocation shifts\n",
    "        drift_pen = np.clip(1e-5 * np.square(delta_w).sum(), 0, 1e-3)\n",
    "\n",
    "        # Aggregate reward components and apply squashing for stability\n",
    "        raw = pnl_ret - risk_pen - tvr_pen - drift_pen\n",
    "        reward = float(np.clip(np.tanh(raw * 20.0), -1.0, 1.0))\n",
    "\n",
    "        info = {\n",
    "            \"pnl_ret\": pnl_ret,\n",
    "            \"risk_pen\": risk_pen,\n",
    "            \"tvr_pen\": tvr_pen,\n",
    "            \"equity\": float(self.equity)\n",
    "        }\n",
    "\n",
    "        # Advance simulation clock and detect terminal state\n",
    "        self.t += 1\n",
    "        done = self.t >= len(self.close) - 1\n",
    "\n",
    "        return self._obs(), reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a62230a7-2f1e-4947-b1c1-0c3f6456a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/env/portfolio_gym.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/env/portfolio_gym.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from src.env.portfolio_env import PortfolioEnv\n",
    "\n",
    "class PortfolioGym(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, prices, feature_df=None, start_equity=1_000_000):\n",
    "        super().__init__()\n",
    "        # Core environment handles portfolio mechanics and reward calculation\n",
    "        self.core = PortfolioEnv(prices, start_equity=start_equity)\n",
    "        self.feature_df = feature_df\n",
    "        self.tickers = self.core.tickers\n",
    "        self.n_assets = len(self.tickers)\n",
    "\n",
    "        # Observation vector consists of equity, portfolio weights, and optional features\n",
    "        feat_dim = 0 if feature_df is None else feature_df.shape[1]\n",
    "        obs_dim = 1 + self.n_assets + feat_dim\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "        # Action space corresponds to target portfolio weights for each asset\n",
    "        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.n_assets,), dtype=np.float32)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        # Reset both the wrapper and the underlying portfolio environment\n",
    "        super().reset(seed=seed)\n",
    "        obs_core = self.core.reset()\n",
    "        obs = self._build_obs(obs_core)\n",
    "        return obs.astype(np.float32), {}\n",
    "\n",
    "    def _build_obs(self, core_obs):\n",
    "        # Construct the observation vector at the current timestep\n",
    "        equity = float(core_obs[\"equity\"])\n",
    "        w = np.array(core_obs[\"weights\"], dtype=np.float32)\n",
    "\n",
    "        if self.feature_df is not None:\n",
    "            # Align features with current environment timestep\n",
    "            t = min(self.core.t, len(self.feature_df) - 1)\n",
    "            f = self.feature_df.iloc[t].to_numpy(dtype=np.float32)\n",
    "            f = np.nan_to_num(f, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            f = (f - np.mean(f)) / (np.std(f) + 1e-8)\n",
    "            obs = np.concatenate(([equity], w, f))\n",
    "        else:\n",
    "            obs = np.concatenate(([equity], w))\n",
    "\n",
    "        return np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    def step(self, action):\n",
    "        # Delegate trade execution and reward calculation to the core environment\n",
    "        obs_core, reward, done, info = self.core.step(action)\n",
    "\n",
    "        # Replace non-finite rewards to avoid propagation of numerical errors\n",
    "        if not np.isfinite(reward):\n",
    "            print(f\"[Warning] Non-finite reward at t={self.core.t}: {reward}\")\n",
    "            reward = 0.0\n",
    "\n",
    "        obs = self._build_obs(obs_core)\n",
    "\n",
    "        # Replace NaNs in observation with zeros to maintain numerical stability\n",
    "        if np.isnan(obs).any():\n",
    "            print(f\"[NaN detected in obs] t={self.core.t}, replacing with zeros.\")\n",
    "            obs = np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if np.isnan(reward):\n",
    "            reward = 0.0\n",
    "\n",
    "        # Clip extreme values to avoid destabilizing the learning process\n",
    "        obs = np.clip(obs, -1e6, 1e6)\n",
    "        reward = float(np.clip(reward, -1e3, 1e3))\n",
    "\n",
    "        # Gymnasium interface compatibility: separate terminated and truncated flags\n",
    "        terminated = bool(done)\n",
    "        truncated = False\n",
    "\n",
    "        return obs.astype(np.float32), reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        # Basic render method for quick debugging or logging\n",
    "        print(f\"Step {self.core.t}, Equity {self.core.equity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5199c8c7-970c-4689-a62c-0e704e86e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/features.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enriches a single-ticker price dataframe with a set of standard technical indicators.\n",
    "    Assumes columns: ['Open', 'High', 'Low', 'Close', 'Volume'].\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Basic return and volatility metrics\n",
    "    df[\"returns\"] = df[\"Close\"].pct_change()\n",
    "    df[\"volatility_20\"] = df[\"returns\"].rolling(20).std()\n",
    "\n",
    "    # Momentum indicators over short and medium windows\n",
    "    df[\"momentum_5\"] = df[\"Close\"].pct_change(5)\n",
    "    df[\"momentum_20\"] = df[\"Close\"].pct_change(20)\n",
    "\n",
    "    # Relative Strength Index (RSI) over a 14-period lookback\n",
    "    delta = df[\"Close\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-9)\n",
    "    df[\"rsi\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    ema12 = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    df[\"macd\"] = ema12 - ema26\n",
    "\n",
    "    # Z-score of price relative to a 20-period rolling mean\n",
    "    df[\"zscore\"] = (df[\"Close\"] - df[\"Close\"].rolling(20).mean()) / (df[\"Close\"].rolling(20).std() + 1e-9)\n",
    "\n",
    "    # Volume change as a percentage\n",
    "    df[\"vol_change\"] = df[\"Volume\"].pct_change()\n",
    "\n",
    "    # Drop initial NaNs introduced by rolling calculations\n",
    "    return df.dropna()\n",
    "\n",
    "def build_all_features(panel):\n",
    "    \"\"\"\n",
    "    Applies the add_features function to each ticker in a multi-index price panel.\n",
    "    Returns a feature panel with a two-level column index: (Ticker, Feature).\n",
    "    \"\"\"\n",
    "    tickers = panel.columns.get_level_values(0).unique()\n",
    "    feat_list = []\n",
    "\n",
    "    # Iterate over tickers and compute features individually\n",
    "    for t in tickers:\n",
    "        df_t = panel[t].copy()\n",
    "        df_feat = add_features(df_t)\n",
    "        feat_list.append(df_feat)\n",
    "\n",
    "    # Combine feature dataframes for all tickers into a single multi-index dataframe\n",
    "    feat = pd.concat(feat_list, axis=1, keys=tickers)\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c586b7a1-fe2e-495f-a742-799d5f81f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/env/portfolio_env.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/env/portfolio_env.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.utils.costs import spread_proxy, realized_vol, participation, exec_price, turnover_l1\n",
    "\n",
    "class PortfolioEnv:\n",
    "    def __init__(\n",
    "        self,\n",
    "        prices,\n",
    "        freq_min=1,\n",
    "        start_equity=1_000_000,\n",
    "        part_cap=0.05,\n",
    "        k=0.6,\n",
    "        lam=2e-4,\n",
    "        gamma_bar=11.0,\n",
    "        eta_turnover=0.001\n",
    "    ):\n",
    "        self.prices = prices\n",
    "        self.close = prices.loc[:, pd.IndexSlice[:, \"Close\"]]\n",
    "        self.high = prices.loc[:, pd.IndexSlice[:, \"High\"]]\n",
    "        self.low = prices.loc[:, pd.IndexSlice[:, \"Low\"]]\n",
    "        self.vol = prices.loc[:, pd.IndexSlice[:, \"Volume\"]]\n",
    "        self.mid = self.close\n",
    "\n",
    "        # Cost and risk model components\n",
    "        self.half_spread = spread_proxy(self.high, self.low)\n",
    "        self.sigma = realized_vol(self.close, win=60)\n",
    "\n",
    "        self.part_cap = part_cap\n",
    "        self.k = k\n",
    "        self.lam = lam\n",
    "        self.freq_min = freq_min\n",
    "        self.gamma = gamma_bar / (252 * 390)  # annualize risk cost\n",
    "        self.eta_turnover = eta_turnover\n",
    "        self.start_equity = start_equity\n",
    "        self.tickers = self.close.columns.get_level_values(0).unique()\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # RESET\n",
    "    # ------------------------------------------------------\n",
    "    def reset(self):\n",
    "        self.t = 1\n",
    "        self.equity = float(self.start_equity)\n",
    "        self.w = np.zeros(len(self.tickers))\n",
    "        self.cash = self.equity\n",
    "        return self._obs()\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # OBSERVATION\n",
    "    # ------------------------------------------------------\n",
    "    def _obs(self):\n",
    "        return {\"weights\": self.w.copy(), \"equity\": float(self.equity)}\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # STEP\n",
    "    # ------------------------------------------------------\n",
    "    def step(self, w_target):\n",
    "        # --- Safety clamp ---\n",
    "        w_target = np.array(w_target).flatten()\n",
    "        w_target = np.clip(w_target, 0, 1)\n",
    "        if w_target.sum() > 0:\n",
    "            w_target /= w_target.sum()\n",
    "\n",
    "        # --- Time + current prices ---\n",
    "        idx = self.close.index[self.t]\n",
    "        idx_next = self.close.index[min(self.t + 1, len(self.close) - 1)]\n",
    "\n",
    "        mid = np.nan_to_num(self.mid.loc[idx].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        hs = np.nan_to_num(self.half_spread.loc[idx].values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        sg = np.nan_to_num(self.sigma.loc[idx].values, nan=1e-6, posinf=1e-6, neginf=1e-6)\n",
    "        vol = np.nan_to_num(self.vol.loc[idx].values, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "\n",
    "        # --- Compute trade ---\n",
    "        delta_w = w_target - self.w\n",
    "        dollar_trade = np.abs(delta_w) * self.equity\n",
    "        part = participation(pd.Series(dollar_trade), pd.Series(mid), pd.Series(vol)).values\n",
    "        part = np.nan_to_num(np.clip(part, 0, self.part_cap), nan=0.0)\n",
    "        side = np.sign(delta_w)\n",
    "\n",
    "        exec_px = np.array([\n",
    "            exec_price(s, m, h, sgm, self.freq_min, p, self.k, self.lam)\n",
    "            for s, m, h, sgm, p in zip(side, mid, hs, sg, part)\n",
    "        ])\n",
    "        exec_px = np.nan_to_num(exec_px, nan=mid, posinf=mid, neginf=mid)\n",
    "\n",
    "        # --- Trade cash impact ---\n",
    "        shares = np.nan_to_num((np.abs(delta_w) * self.equity) / np.maximum(mid, 1e-12))\n",
    "        trade_cash = np.sum(shares * exec_px * side)\n",
    "\n",
    "        # --- Update positions ---\n",
    "        dollar_pos = self.w * self.equity\n",
    "        dollar_pos += shares * exec_px * side\n",
    "        self.equity = np.maximum(self.equity - np.abs(trade_cash), 1.0)\n",
    "        self.cash = max(self.start_equity - np.sum(dollar_pos), 0.0)\n",
    "\n",
    "        next_px = np.nan_to_num(self.mid.loc[idx_next].values, nan=mid, posinf=mid, neginf=mid)\n",
    "        dollar_pos = dollar_pos * (next_px / np.maximum(mid, 1e-12))\n",
    "        self.equity = float(np.nan_to_num(np.sum(dollar_pos) + self.cash, nan=self.start_equity))\n",
    "        self.w = np.clip(np.nan_to_num(dollar_pos / np.maximum(self.equity, 1e-12)), 0, 1)\n",
    "\n",
    "        # --- Penalties ---\n",
    "        var_diag = np.nan_to_num((self.sigma.loc[idx] ** 2).values, nan=0.0)\n",
    "        risk_pen = 0.5 * self.gamma * float(np.dot(self.w, var_diag * self.w))\n",
    "        tvr = turnover_l1(self.w, self.w - delta_w)\n",
    "        tvr_pen = self.eta_turnover * tvr\n",
    "\n",
    "        # --- Reward ---\n",
    "        prev_idx = self.close.index[self.t - 1]\n",
    "        r_bar = np.nan_to_num(\n",
    "            self.mid.loc[idx_next].values / np.maximum(self.mid.loc[prev_idx].values, 1e-12) - 1.0,\n",
    "            nan=0.0,\n",
    "        )\n",
    "        pnl_ret = float(np.dot(self.w, r_bar))\n",
    "\n",
    "        drift_pen = 0.001 * np.square(delta_w).sum()\n",
    "\n",
    "        # --- Reward decomposition ---\n",
    "        # Scale pnl by equity to get relative return per step\n",
    "        step_ret = pnl_ret\n",
    "\n",
    "        # Risk penalty scaled down: risk cost shouldn't dwarf pnl\n",
    "        risk_pen_scaled = 0.1 * risk_pen\n",
    "\n",
    "        # Turnover penalty usually small relative to pnl\n",
    "        tvr_pen_scaled = tvr_pen\n",
    "\n",
    "        # Drift penalty already tiny\n",
    "        drift_pen_scaled = drift_pen\n",
    "\n",
    "        # Raw reward\n",
    "        raw_reward = step_ret - risk_pen_scaled - tvr_pen_scaled - drift_pen_scaled\n",
    "\n",
    "        # Normalize by a typical step volatility to keep magnitude reasonable\n",
    "        reward_norm = raw_reward / (np.std([step_ret, risk_pen_scaled, tvr_pen_scaled, 1e-6]) + 1e-6)\n",
    "\n",
    "        # Soft clipping to avoid tanh saturation\n",
    "        reward = float(np.clip(reward_norm, -5.0, 5.0))\n",
    "\n",
    "\n",
    "        # --- Stability guards ---\n",
    "        reward = float(np.nan_to_num(reward, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "        self.equity = float(np.nan_to_num(self.equity, nan=self.start_equity, posinf=self.start_equity, neginf=self.start_equity))\n",
    "\n",
    "        # Scale reward\n",
    "        \n",
    "\n",
    "        info = {\n",
    "            \"pnl_ret\": pnl_ret,\n",
    "            \"risk_pen\": risk_pen,\n",
    "            \"tvr_pen\": tvr_pen,\n",
    "            \"equity\": float(self.equity)\n",
    "        }\n",
    "\n",
    "        self.t += 1\n",
    "        done = self.t >= len(self.close) - 1\n",
    "        return self._obs(), reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdda85-fcbb-4fab-acbd-710e97e47e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
