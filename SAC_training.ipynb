{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75555c85-53e6-4c29-b119-fe67bfd99e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.env.portfolio_gym import PortfolioGym\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "panel = pd.read_pickle(\"data/processed/etfs_1m_clean.pkl\")\n",
    "\n",
    "# Sort just in case\n",
    "panel = panel.sort_index()\n",
    "\n",
    "# Determine split index (e.g. 80% train)\n",
    "split_idx = int(len(panel.index) * 0.8)\n",
    "train_panel = panel.iloc[:split_idx]\n",
    "test_panel = panel.iloc[split_idx:]\n",
    "\n",
    "from src.env.portfolio_env import PortfolioEnv\n",
    "\n",
    "train_env = PortfolioEnv(train_panel, start_equity=1_000_000)\n",
    "test_env = PortfolioEnv(test_panel, start_equity=1_000_000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3beca1-3e5f-463f-ba24-e942c9e4fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium==1.0.0\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from gymnasium==1.0.0) (2.3.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from gymnasium==1.0.0) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from gymnasium==1.0.0) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from gymnasium==1.0.0) (0.0.4)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from stable-baselines3[extra]) (2.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from stable-baselines3[extra]) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from stable-baselines3[extra]) (3.10.6)\n",
      "Collecting opencv-python (from stable-baselines3[extra])\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pygame (from stable-baselines3[extra])\n",
      "  Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Collecting tqdm (from stable-baselines3[extra])\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting rich (from stable-baselines3[extra])\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
      "  Downloading ale_py-0.11.2-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from stable-baselines3[extra]) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.17.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading grpcio-1.75.1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.32.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (72.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.17.0)\n",
      "Collecting numpy>=1.21.0 (from gymnasium==1.0.0)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra])\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra])\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mithi\\miniconda3\\envs\\drl\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "   ---------------------------------------- 0.0/958.1 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/958.1 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 786.4/958.1 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 958.1/958.1 kB 2.2 MB/s  0:00:00\n",
      "Downloading ale_py-0.11.2-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.0/3.5 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.8/3.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.1/3.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 4.8 MB/s  0:00:00\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.5 MB/s  0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading grpcio-1.75.1-cp311-cp311-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.6/4.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.9/4.6 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.6 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 7.6 MB/s  0:00:00\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/39.0 MB 5.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.6/39.0 MB 4.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.1/39.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.9/39.0 MB 5.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 5.0/39.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 6.0/39.0 MB 4.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.3/39.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.3/39.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.3/39.0 MB 5.0 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 8.1/39.0 MB 3.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 9.7/39.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 11.3/39.0 MB 4.5 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.3/39.0 MB 4.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 13.4/39.0 MB 4.6 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 14.7/39.0 MB 4.7 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 16.0/39.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.0/39.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.4/39.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 19.4/39.0 MB 4.9 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 20.7/39.0 MB 5.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.3/39.0 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.6/39.0 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.9/39.0 MB 5.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 26.5/39.0 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 27.0/39.0 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.8/39.0 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.4/39.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.4/39.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 31.2/39.0 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.8/39.0 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 34.1/39.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.9/39.0 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.2/39.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 5.5 MB/s  0:00:07\n",
      "Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 7.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.2/12.9 MB 6.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.9 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.7/12.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.9 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 5.2 MB/s  0:00:02\n",
      "Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 7.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/10.6 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/10.6 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.5/10.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.8/10.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.4/10.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 6.2 MB/s  0:00:01\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: werkzeug, tqdm, tensorboard-data-server, pygame, numpy, mdurl, markdown, grpcio, absl-py, tensorboard, opencv-python, markdown-it-py, gymnasium, ale-py, rich\n",
      "\n",
      "   ----------------------------------------  0/15 [werkzeug]\n",
      "   -- -------------------------------------  1/15 [tqdm]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "  Attempting uninstall: numpy\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "    Found existing installation: numpy 2.3.1\n",
      "   -------- -------------------------------  3/15 [pygame]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "    Uninstalling numpy-2.3.1:\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------- -----------------------------  4/15 [numpy]\n",
      "   ---------------- -----------------------  6/15 [markdown]\n",
      "   ------------------ ---------------------  7/15 [grpcio]\n",
      "   ------------------ ---------------------  7/15 [grpcio]\n",
      "   --------------------- ------------------  8/15 [absl-py]\n",
      "   ------------------------ ---------------  9/15 [tensorboard]\n",
      "   ------------------------ ---------------  9/15 [tensorboard]\n",
      "   ------------------------ ---------------  9/15 [tensorboard]\n",
      "   ------------------------ ---------------  9/15 [tensorboard]\n",
      "   ------------------------ ---------------  9/15 [tensorboard]\n",
      "   ------------------------ ---------------  9/15 [tensorboard]\n",
      "   ------------------------ ---------------  9/15 [tensorboard]\n",
      "   -------------------------- ------------- 10/15 [opencv-python]\n",
      "   -------------------------- ------------- 10/15 [opencv-python]\n",
      "   -------------------------- ------------- 10/15 [opencv-python]\n",
      "   ----------------------------- ---------- 11/15 [markdown-it-py]\n",
      "   ----------------------------- ---------- 11/15 [markdown-it-py]\n",
      "  Attempting uninstall: gymnasium\n",
      "   ----------------------------- ---------- 11/15 [markdown-it-py]\n",
      "    Found existing installation: gymnasium 1.2.1\n",
      "   ----------------------------- ---------- 11/15 [markdown-it-py]\n",
      "   -------------------------------- ------- 12/15 [gymnasium]\n",
      "    Uninstalling gymnasium-1.2.1:\n",
      "   -------------------------------- ------- 12/15 [gymnasium]\n",
      "      Successfully uninstalled gymnasium-1.2.1\n",
      "   -------------------------------- ------- 12/15 [gymnasium]\n",
      "   -------------------------------- ------- 12/15 [gymnasium]\n",
      "   -------------------------------- ------- 12/15 [gymnasium]\n",
      "   -------------------------------- ------- 12/15 [gymnasium]\n",
      "   -------------------------------- ------- 12/15 [gymnasium]\n",
      "   ---------------------------------- ----- 13/15 [ale-py]\n",
      "   ------------------------------------- -- 14/15 [rich]\n",
      "   ------------------------------------- -- 14/15 [rich]\n",
      "   ------------------------------------- -- 14/15 [rich]\n",
      "   ---------------------------------------- 15/15 [rich]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 ale-py-0.11.2 grpcio-1.75.1 gymnasium-1.0.0 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 numpy-2.2.6 opencv-python-4.12.0.88 pygame-2.6.1 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tqdm-4.67.1 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stable-baselines3[extra] gymnasium==1.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647ac2ad-2b18-4620-adc6-3715263fcdcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCUDA available:\u001b[39m\u001b[33m\"\u001b[39m, torch.cuda.is_available())\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\__init__.py:2475\u001b[39m\n\u001b[32m   2471\u001b[39m     torch_module_name = \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[34m__name__\u001b[39m, device_type])\n\u001b[32m   2472\u001b[39m     sys.modules[torch_module_name] = module\n\u001b[32m-> \u001b[39m\u001b[32m2475\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m   2476\u001b[39m     export \u001b[38;5;28;01mas\u001b[39;00m export,\n\u001b[32m   2477\u001b[39m     func \u001b[38;5;28;01mas\u001b[39;00m func,\n\u001b[32m   2478\u001b[39m     library \u001b[38;5;28;01mas\u001b[39;00m library,\n\u001b[32m   2479\u001b[39m     return_types \u001b[38;5;28;01mas\u001b[39;00m return_types,\n\u001b[32m   2480\u001b[39m )\n\u001b[32m   2481\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cond \u001b[38;5;28;01mas\u001b[39;00m cond, while_loop \u001b[38;5;28;01mas\u001b[39;00m while_loop\n\u001b[32m   2482\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\export\\__init__.py:64\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrictMinMaxConstraint\n\u001b[32m     44\u001b[39m __all__ = [\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mConstraint\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDim\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUnflattenedModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     61\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdynamic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Constraint, Dim, dims, ShapesCollection\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexported_program\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_signature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportBackwardSignature, ExportGraphSignature\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     _get_node_type,\n\u001b[32m     13\u001b[39m     BUILTIN_TYPES,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     tree_map_with_path,\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexported_program\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Symbol\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\export\\exported_program.py:26\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     Any,\n\u001b[32m     14\u001b[39m     Callable,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     Union,\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograd_not_implemented\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_library\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_class_registry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeScriptObject\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m first_call_function_nn_module_stack\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcond\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cond\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     flex_attention,\n\u001b[32m      4\u001b[39m     flex_attention_backward,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhints_wrap\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hints_wrapper\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional_tensor\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytree\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DispatchKey\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minductor_config\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytree\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _functionalization_reapply_views_tls \u001b[38;5;28;01mas\u001b[39;00m _reapply_views\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\_inductor\\config.py:44\u001b[39m\n\u001b[32m     40\u001b[39m verbose_progress = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# use fx aot graph codegen cache\u001b[39;00m\n\u001b[32m     43\u001b[39m fx_graph_cache = (\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mTORCHINDUCTOR_FX_GRAPH_CACHE\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_fbcode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# use remote fx aot graph codegen cache\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# False: Disables the cache\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# True: Enables the cache\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001b[39;00m\n\u001b[32m     51\u001b[39m fx_graph_remote_cache: Optional[\u001b[38;5;28mbool\u001b[39m] = fx_graph_remote_cache_default()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\_inductor\\config.py:9\u001b[39m, in \u001b[36mis_fbcode\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_fbcode\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mgit_version\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"⚠️ CUDA not detected — running on CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c9f684-37e7-4cd4-80ad-fdacb2ff8adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1\n",
      "Uninstalling torch-2.5.1:\n",
      "  Successfully uninstalled torch-2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbd6ca2-91d3-4b83-90a4-717d4459f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Acer\n",
      " Volume Serial Number is 3E80-FBD3\n",
      "\n",
      " Directory of C:\\Users\\mithi\\drl-portfolio-allocation\n",
      "\n",
      "13/10/2025  13:12    <DIR>          .\n",
      "11/10/2025  21:37    <DIR>          ..\n",
      "10/10/2025  03:01                83 .gitignore\n",
      "11/10/2025  23:38    <DIR>          .ipynb_checkpoints\n",
      "11/10/2025  11:20    <DIR>          data\n",
      "13/10/2025  11:37    <DIR>          logs\n",
      "13/10/2025  12:44    <DIR>          models\n",
      "11/10/2025  23:38            41,800 notebook_1_ data_wrangling_and_feature_engineering.ipynb\n",
      "10/10/2025  02:52                26 README.md\n",
      "11/10/2025  22:56    <DIR>          src\n",
      "11/10/2025  23:03             8,986 test.ipynb\n",
      "13/10/2025  13:12            87,369 Untitled.ipynb\n",
      "               5 File(s)        138,264 bytes\n",
      "               7 Dir(s)  113,797,763,072 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c5def8-94cb-4e7c-af82-8a19ca98a68a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _C: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCUDA available:\u001b[39m\u001b[33m\"\u001b[39m, torch.cuda.is_available())\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\drl\\Lib\\site-packages\\torch\\__init__.py:367\u001b[39m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[32m    366\u001b[39m         _load_global_deps()\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSymInt\u001b[39;00m:\n\u001b[32m    371\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _C: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"⚠️ CUDA not detected — running on CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791214d8-0621-45ff-95d8-3d6cced0e643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1824, Test size: 456\n",
      "Using device: cuda\n",
      "Using cuda device\n",
      "Logging to logs/sac_portfolio/SAC_5\n",
      "Eval num_timesteps=5000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0224  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 11.3     |\n",
      "|    ent_coef        | 0.239    |\n",
      "|    ent_coef_loss   | -22.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4928     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.34    |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 30       |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 7288     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -160     |\n",
      "|    critic_loss     | 7.81     |\n",
      "|    ent_coef        | 0.135    |\n",
      "|    ent_coef_loss   | -28.3    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7168     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0224  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -114     |\n",
      "|    critic_loss     | 1.14     |\n",
      "|    ent_coef        | 0.0824   |\n",
      "|    ent_coef_loss   | 6.4      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9920     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.14    |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 456      |\n",
      "|    total_timesteps | 14576    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59.5    |\n",
      "|    critic_loss     | 1.56     |\n",
      "|    ent_coef        | 0.0401   |\n",
      "|    ent_coef_loss   | 4.04     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14464    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0245  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 15000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.2    |\n",
      "|    critic_loss     | 2.77     |\n",
      "|    ent_coef        | 0.0359   |\n",
      "|    ent_coef_loss   | -38      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14912    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-0.40 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.396   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28      |\n",
      "|    critic_loss     | 0.233    |\n",
      "|    ent_coef        | 0.0105   |\n",
      "|    ent_coef_loss   | -16.8    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19904    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.14    |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 32       |\n",
      "|    time_elapsed    | 678      |\n",
      "|    total_timesteps | 21864    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.7    |\n",
      "|    critic_loss     | 0.243    |\n",
      "|    ent_coef        | 0.0117   |\n",
      "|    ent_coef_loss   | 5.62     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21760    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0226  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 25000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14      |\n",
      "|    critic_loss     | 0.145    |\n",
      "|    ent_coef        | 0.00971  |\n",
      "|    ent_coef_loss   | -28.1    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24896    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.09    |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 32       |\n",
      "|    time_elapsed    | 894      |\n",
      "|    total_timesteps | 29152    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.13    |\n",
      "|    critic_loss     | 0.0434   |\n",
      "|    ent_coef        | 0.00433  |\n",
      "|    ent_coef_loss   | 0.871    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29056    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-0.25 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.248   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.92    |\n",
      "|    critic_loss     | 0.0262   |\n",
      "|    ent_coef        | 0.00486  |\n",
      "|    ent_coef_loss   | 6.02     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29888    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0186  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 35000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.94    |\n",
      "|    critic_loss     | 0.00953  |\n",
      "|    ent_coef        | 0.00373  |\n",
      "|    ent_coef_loss   | -5.91    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34880    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.02    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 32       |\n",
      "|    time_elapsed    | 1110     |\n",
      "|    total_timesteps | 36440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.72    |\n",
      "|    critic_loss     | 0.0118   |\n",
      "|    ent_coef        | 0.00229  |\n",
      "|    ent_coef_loss   | -75.1    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36352    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-0.57 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.566   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.42    |\n",
      "|    critic_loss     | 0.00478  |\n",
      "|    ent_coef        | 0.00239  |\n",
      "|    ent_coef_loss   | -28.7    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39872    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.04    |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 1320     |\n",
      "|    total_timesteps | 43728    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.97    |\n",
      "|    critic_loss     | 0.00261  |\n",
      "|    ent_coef        | 0.00175  |\n",
      "|    ent_coef_loss   | 55.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 43648    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0249  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 45000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.58    |\n",
      "|    critic_loss     | 0.00151  |\n",
      "|    ent_coef        | 0.00194  |\n",
      "|    ent_coef_loss   | -30.2    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 44928    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-0.45 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.452   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 50000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.797   |\n",
      "|    critic_loss     | 0.000537 |\n",
      "|    ent_coef        | 0.00053  |\n",
      "|    ent_coef_loss   | -9.23    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 49920    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.04    |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 1532     |\n",
      "|    total_timesteps | 51016    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.831   |\n",
      "|    critic_loss     | 0.000529 |\n",
      "|    ent_coef        | 0.000644 |\n",
      "|    ent_coef_loss   | 27.4     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 50944    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-0.51 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.511   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 55000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.518   |\n",
      "|    critic_loss     | 0.000257 |\n",
      "|    ent_coef        | 0.000455 |\n",
      "|    ent_coef_loss   | 0.0587   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 54912    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.05    |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 1740     |\n",
      "|    total_timesteps | 58304    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.464   |\n",
      "|    critic_loss     | 0.00039  |\n",
      "|    ent_coef        | 0.000687 |\n",
      "|    ent_coef_loss   | -0.165   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 58176    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0286  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.388   |\n",
      "|    critic_loss     | 0.00021  |\n",
      "|    ent_coef        | 0.000379 |\n",
      "|    ent_coef_loss   | -13.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 59904    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0191  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 65000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.163   |\n",
      "|    critic_loss     | 0.000143 |\n",
      "|    ent_coef        | 0.000343 |\n",
      "|    ent_coef_loss   | 43.4     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 64896    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -1.01    |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 1954     |\n",
      "|    total_timesteps | 65592    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.161   |\n",
      "|    critic_loss     | 8.19e-05 |\n",
      "|    ent_coef        | 0.000389 |\n",
      "|    ent_coef_loss   | 0.862    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 65472    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0285  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 70000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.178   |\n",
      "|    critic_loss     | 0.000498 |\n",
      "|    ent_coef        | 0.00024  |\n",
      "|    ent_coef_loss   | 120      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 69888    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.978   |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 2150     |\n",
      "|    total_timesteps | 72880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.295   |\n",
      "|    critic_loss     | 0.000108 |\n",
      "|    ent_coef        | 0.000265 |\n",
      "|    ent_coef_loss   | 122      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 72768    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0284  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 75000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0542   |\n",
      "|    critic_loss     | 0.000136 |\n",
      "|    ent_coef        | 0.000545 |\n",
      "|    ent_coef_loss   | 79.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 74880    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.029   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0162   |\n",
      "|    critic_loss     | 0.000336 |\n",
      "|    ent_coef        | 0.000261 |\n",
      "|    ent_coef_loss   | 109      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 79872    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.924   |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 2355     |\n",
      "|    total_timesteps | 80168    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0175  |\n",
      "|    critic_loss     | 0.000128 |\n",
      "|    ent_coef        | 0.000278 |\n",
      "|    ent_coef_loss   | 33.9     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 80064    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 85000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0856   |\n",
      "|    critic_loss     | 6.85e-05 |\n",
      "|    ent_coef        | 0.000274 |\n",
      "|    ent_coef_loss   | -121     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 84928    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.901   |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 2551     |\n",
      "|    total_timesteps | 87456    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0574   |\n",
      "|    critic_loss     | 3.93e-05 |\n",
      "|    ent_coef        | 0.000148 |\n",
      "|    ent_coef_loss   | 12.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 87360    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0192  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 90000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.00732  |\n",
      "|    critic_loss     | 8e-05    |\n",
      "|    ent_coef        | 0.00018  |\n",
      "|    ent_coef_loss   | -18.8    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 89920    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.889   |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 2747     |\n",
      "|    total_timesteps | 94744    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0442  |\n",
      "|    critic_loss     | 3.2e-05  |\n",
      "|    ent_coef        | 0.000117 |\n",
      "|    ent_coef_loss   | 108      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 94656    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-0.35 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.354   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 95000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0516  |\n",
      "|    critic_loss     | 2.11e-05 |\n",
      "|    ent_coef        | 0.000126 |\n",
      "|    ent_coef_loss   | 96.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 94912    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-0.14 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.143   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.00149  |\n",
      "|    critic_loss     | 4.08e-05 |\n",
      "|    ent_coef        | 0.000153 |\n",
      "|    ent_coef_loss   | 23.4     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 99904    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.889   |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 2973     |\n",
      "|    total_timesteps | 102032   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0284   |\n",
      "|    critic_loss     | 4.23e-05 |\n",
      "|    ent_coef        | 0.000246 |\n",
      "|    ent_coef_loss   | -15.3    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 101952   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-0.37 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.37    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 105000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0148   |\n",
      "|    critic_loss     | 1.97e-05 |\n",
      "|    ent_coef        | 0.000173 |\n",
      "|    ent_coef_loss   | -91      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 104896   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.879   |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 3085     |\n",
      "|    total_timesteps | 109320   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.00578  |\n",
      "|    critic_loss     | 4.83e-05 |\n",
      "|    ent_coef        | 0.000112 |\n",
      "|    ent_coef_loss   | 53.7     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 109248   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0241  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 110000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0114   |\n",
      "|    critic_loss     | 1.91e-05 |\n",
      "|    ent_coef        | 0.000121 |\n",
      "|    ent_coef_loss   | -30      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 109888   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0266  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 115000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0188   |\n",
      "|    critic_loss     | 2.03e-05 |\n",
      "|    ent_coef        | 7.4e-05  |\n",
      "|    ent_coef_loss   | 64       |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 114880   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.854   |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 36       |\n",
      "|    time_elapsed    | 3204     |\n",
      "|    total_timesteps | 116608   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0367   |\n",
      "|    critic_loss     | 1.46e-05 |\n",
      "|    ent_coef        | 0.000106 |\n",
      "|    ent_coef_loss   | 23.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 116480   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0244  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 120000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0471   |\n",
      "|    critic_loss     | 1.52e-05 |\n",
      "|    ent_coef        | 0.000125 |\n",
      "|    ent_coef_loss   | 1.16     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 119872   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.835   |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 37       |\n",
      "|    time_elapsed    | 3312     |\n",
      "|    total_timesteps | 123896   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0428   |\n",
      "|    critic_loss     | 1.66e-05 |\n",
      "|    ent_coef        | 0.000113 |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 123776   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.025   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 125000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0447   |\n",
      "|    critic_loss     | 7.48e-05 |\n",
      "|    ent_coef        | 0.000113 |\n",
      "|    ent_coef_loss   | -6.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 124928   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0246  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 130000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0436   |\n",
      "|    critic_loss     | 2.99e-05 |\n",
      "|    ent_coef        | 0.0001   |\n",
      "|    ent_coef_loss   | -1.37    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 129920   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.823   |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 38       |\n",
      "|    time_elapsed    | 3423     |\n",
      "|    total_timesteps | 131184   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0428   |\n",
      "|    critic_loss     | 2.08e-05 |\n",
      "|    ent_coef        | 9.57e-05 |\n",
      "|    ent_coef_loss   | -1.55    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 131072   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0272  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 135000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0428   |\n",
      "|    critic_loss     | 1.93e-05 |\n",
      "|    ent_coef        | 9.12e-05 |\n",
      "|    ent_coef_loss   | -1.55    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 134912   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.809   |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 3527     |\n",
      "|    total_timesteps | 138472   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0424   |\n",
      "|    critic_loss     | 1.13e-05 |\n",
      "|    ent_coef        | 9.29e-05 |\n",
      "|    ent_coef_loss   | 5.72     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 138368   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0275  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 140000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0427   |\n",
      "|    critic_loss     | 1.5e-05  |\n",
      "|    ent_coef        | 9.82e-05 |\n",
      "|    ent_coef_loss   | -5.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 139904   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0263  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 145000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0427   |\n",
      "|    critic_loss     | 1.06e-05 |\n",
      "|    ent_coef        | 9.52e-05 |\n",
      "|    ent_coef_loss   | -1.14    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 144896   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.798   |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 3638     |\n",
      "|    total_timesteps | 145760   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0443   |\n",
      "|    critic_loss     | 2.42e-05 |\n",
      "|    ent_coef        | 9.13e-05 |\n",
      "|    ent_coef_loss   | -2.31    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 145664   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0276  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 150000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0475   |\n",
      "|    critic_loss     | 3.25e-05 |\n",
      "|    ent_coef        | 8.1e-05  |\n",
      "|    ent_coef_loss   | 11.9     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 149888   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.786   |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 3743     |\n",
      "|    total_timesteps | 153048   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0454   |\n",
      "|    critic_loss     | 1.79e-05 |\n",
      "|    ent_coef        | 7e-05    |\n",
      "|    ent_coef_loss   | 9.76     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 152960   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.028   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 155000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0383   |\n",
      "|    critic_loss     | 1.04e-05 |\n",
      "|    ent_coef        | 6.22e-05 |\n",
      "|    ent_coef_loss   | -53.4    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 154880   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-0.21 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.213   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 160000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0413   |\n",
      "|    critic_loss     | 1.31e-05 |\n",
      "|    ent_coef        | 9.59e-05 |\n",
      "|    ent_coef_loss   | 71.6     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 159872   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.777   |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 3854     |\n",
      "|    total_timesteps | 160336   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0492   |\n",
      "|    critic_loss     | 2.52e-05 |\n",
      "|    ent_coef        | 0.000104 |\n",
      "|    ent_coef_loss   | -2.22    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 160256   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0226  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 165000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0329   |\n",
      "|    critic_loss     | 7.01e-06 |\n",
      "|    ent_coef        | 6.06e-05 |\n",
      "|    ent_coef_loss   | 65.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 164928   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.761   |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 3962     |\n",
      "|    total_timesteps | 167624   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0421   |\n",
      "|    critic_loss     | 5.89e-06 |\n",
      "|    ent_coef        | 7.65e-05 |\n",
      "|    ent_coef_loss   | -14.4    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 167552   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0178  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 170000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0346   |\n",
      "|    critic_loss     | 1e-05    |\n",
      "|    ent_coef        | 7.96e-05 |\n",
      "|    ent_coef_loss   | 20.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 169920   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.752   |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 4068     |\n",
      "|    total_timesteps | 174912   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0341   |\n",
      "|    critic_loss     | 1.43e-05 |\n",
      "|    ent_coef        | 9.84e-05 |\n",
      "|    ent_coef_loss   | 10.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 174784   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0186  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 175000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0342   |\n",
      "|    critic_loss     | 1.16e-05 |\n",
      "|    ent_coef        | 9.96e-05 |\n",
      "|    ent_coef_loss   | 0.722    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 174912   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.018   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 180000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0322   |\n",
      "|    critic_loss     | 8.41e-06 |\n",
      "|    ent_coef        | 9.74e-05 |\n",
      "|    ent_coef_loss   | -17      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 179904   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.743   |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4178     |\n",
      "|    total_timesteps | 182200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0318   |\n",
      "|    critic_loss     | 6.93e-06 |\n",
      "|    ent_coef        | 7.19e-05 |\n",
      "|    ent_coef_loss   | -1.81    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 182080   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0228  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 185000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0316   |\n",
      "|    critic_loss     | 4.61e-06 |\n",
      "|    ent_coef        | 8.56e-05 |\n",
      "|    ent_coef_loss   | 0.68     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 184896   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.714   |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 4285     |\n",
      "|    total_timesteps | 189488   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0269   |\n",
      "|    critic_loss     | 7.51e-06 |\n",
      "|    ent_coef        | 3.19e-05 |\n",
      "|    ent_coef_loss   | -60.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 189376   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0237  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 190000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0278   |\n",
      "|    critic_loss     | 1.2e-05  |\n",
      "|    ent_coef        | 2.98e-05 |\n",
      "|    ent_coef_loss   | -23.8    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 189888   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0247  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 195000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0376   |\n",
      "|    critic_loss     | 8.83e-06 |\n",
      "|    ent_coef        | 3.51e-05 |\n",
      "|    ent_coef_loss   | -127     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 194880   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | -0.691   |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 4409     |\n",
      "|    total_timesteps | 196776   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0303   |\n",
      "|    critic_loss     | 3.61e-06 |\n",
      "|    ent_coef        | 3.85e-05 |\n",
      "|    ent_coef_loss   | 63.9     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 196672   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 454      |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 200000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0327   |\n",
      "|    critic_loss     | 6.2e-06  |\n",
      "|    ent_coef        | 5.82e-05 |\n",
      "|    ent_coef_loss   | -21.5    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 199872   |\n",
      "---------------------------------\n",
      "✅ Training complete — model saved to models/sac_portfolio\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from src.env.portfolio_gym import PortfolioGym\n",
    "\n",
    "# ✅ 1️⃣ Load and split data\n",
    "panel = pd.read_pickle(\"data/processed/etfs_1m_clean.pkl\")\n",
    "panel = panel.sort_index()\n",
    "\n",
    "split_idx = int(len(panel.index) * 0.8)\n",
    "train_panel = panel.iloc[:split_idx]\n",
    "test_panel = panel.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train size: {len(train_panel)}, Test size: {len(test_panel)}\")\n",
    "\n",
    "# ✅ 2️⃣ Environment factories\n",
    "def make_train_env():\n",
    "    env = PortfolioGym(train_panel)\n",
    "    return Monitor(env)\n",
    "\n",
    "def make_test_env():\n",
    "    env = PortfolioGym(test_panel)\n",
    "    return Monitor(env)\n",
    "\n",
    "train_env = DummyVecEnv([make_train_env])\n",
    "eval_env = DummyVecEnv([make_test_env])\n",
    "\n",
    "# ✅ 3️⃣ Detect GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ✅ 4️⃣ SAC setup for 2-minute data\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    learning_rate=3e-4,\n",
    "    buffer_size=100_000,\n",
    "    batch_size=256,\n",
    "    tau=0.02,\n",
    "    gamma=0.99,\n",
    "    train_freq=64,\n",
    "    gradient_steps=64,\n",
    "    ent_coef=\"auto\",\n",
    "    target_entropy=\"auto\",\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"logs/sac_portfolio/\",\n",
    "    device=device  # 👈 enables GPU acceleration\n",
    ")\n",
    "\n",
    "# ✅ 5️⃣ Evaluation callback on test set\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"logs/best/\",\n",
    "    log_path=\"logs/results/\",\n",
    "    eval_freq=5000,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "# ✅ 6️⃣ Train\n",
    "model.learn(total_timesteps=200_000, callback=eval_callback)\n",
    "\n",
    "# ✅ 7️⃣ Save model\n",
    "model.save(\"models/sac_portfolio\")\n",
    "\n",
    "print(\"✅ Training complete — model saved to models/sac_portfolio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f89103-a122-4d1c-ad84-77e86703732d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DummyVecEnv' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43meval_env\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: 'DummyVecEnv' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(eval_env[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aee72257-7004-48c6-a711-484c69e6152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final equity: 1000234.4699150745\n",
      "Mean reward: -4.148195e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'eval_envs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     22\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33mEquity\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43meval_envs\u001b[49m[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'eval_envs' is not defined"
     ]
    }
   ],
   "source": [
    "obs = eval_env.reset()\n",
    "equities = []\n",
    "rewards = []\n",
    "\n",
    "for _ in range(500):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = eval_env.step(action)\n",
    "    equities.append(info[0].get(\"equity\"))\n",
    "    rewards.append(reward[0])\n",
    "    if done[0]:\n",
    "        break\n",
    "\n",
    "print(\"Final equity:\", equities[-1])\n",
    "print(\"Mean reward:\", np.mean(rewards))\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(equities)\n",
    "plt.title(\"SAC Portfolio Test Equity Curve\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Equity\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(eval_envs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e05d7e1-f0ec-4a50-93e6-e1182df08720",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m obs, reward, done, info = eval_env.step(action)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m equities.append(\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mequity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "\n",
    "model = SAC.load(\"models/sac_portfolio\")\n",
    "obs = eval_env.reset()\n",
    "\n",
    "equities = []\n",
    "for _ in range(len(test_panel)):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = eval_env.step(action)\n",
    "    equities.append(info[\"equity\"])\n",
    "    if done:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c432c9f-6c2f-453c-a875-957fa0f75a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
